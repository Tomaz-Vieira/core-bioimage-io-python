{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daf2216",
   "metadata": {},
   "source": [
    "# bioimageio.core usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ba149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "import bioimageio.core\n",
    "import imageio\n",
    "\n",
    "# we use napari for visualising images, you can install it via `pip install napari` or`conda install napari`\n",
    "import napari\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74613461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for showing multiple images in napari\n",
    "def show_images(*images, names=None):\n",
    "    v = napari.Viewer()\n",
    "    for i, im in enumerate(images):\n",
    "        name = None if names is None else names[i]\n",
    "        if isinstance(im, str):\n",
    "            im = imageio.imread(im)\n",
    "        v.add_image(im, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2deb81f",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "\n",
    "We will use a model that predicts foreground and boundaries in images of nuclei from the [kaggle nucles segmentation challenge](https://www.kaggle.com/c/data-science-bowl-2018).\n",
    "Find the model on bioimage.io here: https://bioimage.io/#/?id=10.5281%2Fzenodo.5764892\n",
    "\n",
    "First, we will use `bioimageio.core.load_resource_description` to load the model and inspec the obtained model resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de51dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model can be loaded using different representations:\n",
    "\n",
    "# the doi of the zenodo entry corresponding to the model\n",
    "rdf_doi = \"10.5281/zenodo.6287342\"\n",
    "\n",
    "# the url of the yaml file containing the model resource description\n",
    "rdf_url = \"https://zenodo.org/record/6287342/files/rdf.yaml\"\n",
    "\n",
    "# filepath to the downloaded model (either zipped package or yaml)\n",
    "# to download it from the website:\n",
    "# - go to https://bioimage.io/#/?id=10.5281%2Fzenodo.5764892%2F5764893\n",
    "# - click the download icon\n",
    "# - select \"ilastik\" weight format\n",
    "rdf_path = (\n",
    "    \"/home/pape/Downloads/nuclei-segmentation-boundarymodel_pytorch_state_dict.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce884f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from link to rdf.yaml\n",
    "model_resource = bioimageio.core.load_resource_description(rdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1230b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from doi\n",
    "model_resource = bioimageio.core.load_resource_description(rdf_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from path to the zipped model files\n",
    "model_resource = bioimageio.core.load_resource_description(rdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the \"model_resource\" instance returned by load_resource_description\n",
    "# contains the information stored in the resource description (see https://github.com/bioimage-io/spec-bioimage-io/blob/gh-pages/model_spec_latest.md)\n",
    "\n",
    "# we can e.g. check what weight formats are available in the model (pytorch_state_dict for the model used here)\n",
    "print(\"Available weight formats for this model:\", model_resource.weights.keys())\n",
    "# or where the (downloaded) weight files are stored\n",
    "print(\n",
    "    \"Pytorch state dict weights are stored at:\",\n",
    "    model_resource.weights[\"pytorch_state_dict\"].source,\n",
    ")\n",
    "print()\n",
    "# or what inputs the model expects\n",
    "print(\"The model requires as inputs:\")\n",
    "for inp in model_resource.inputs:\n",
    "    print(\"Input with axes:\", inp.axes, \"and shape\", inp.shape)\n",
    "print()\n",
    "# and what the model outputs are\n",
    "print(\"The model returns the following outputs:\")\n",
    "for out in model_resource.outputs:\n",
    "    print(\"Output with axes:\", out.axes, \"and shape\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f21529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function 'test_model' from 'bioimageio.core.resource_tests' can be used to fully test the model,\n",
    "# including running prediction for the test input(s) and checking that they agree with the test output(s)\n",
    "# before using a model, it is recommended to check that it properly works with this function\n",
    "# 'test_model' returns a dict with 'status'='passed'/'failed' and more detailed information\n",
    "from bioimageio.core.resource_tests import test_model\n",
    "\n",
    "test_result = test_model(model_resource)\n",
    "if test_result[\"status\"] == \"failed\":\n",
    "    print(\"model test:\", test_result[\"name\"])\n",
    "    print(\"The model test failed with:\", test_result[\"error\"])\n",
    "    print(\"with the traceback:\")\n",
    "    print(\"\".join(test_result[\"traceback\"]))\n",
    "else:\n",
    "    test_result[\"status\"] == \"passed\"\n",
    "    print(\"The model passed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c75014",
   "metadata": {},
   "source": [
    "## Prediction with the model\n",
    "\n",
    "`bioimageio.core` implements functionality to run prediction with models in the `bioimage.io` format.\n",
    "This includes functions to run prediction with `xarray.DataArrays` as input and convenience functions to run predictions for images stored on disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the example image for this model, which is stored in numpy file format.\n",
    "input_image = np.load(model_resource.test_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an xarray.DataArray from the input image.\n",
    "# DataArrays are like numpy arrays, but they have annotated axes.\n",
    "# The axes are used to validate that the axes of the input image match the axes expected by a model.\n",
    "input_array = xr.DataArray(input_image, dims=tuple(model_resource.inputs[0].axes))\n",
    "# print the axis annotations ('dims') and the shape of the input array\n",
    "print(input_array.dims)\n",
    "print(input_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, create a 'prediction_pipeline'. The prediction_pipeline is used to run prediction with a given model.\n",
    "# This means it applies the preprocessing, runs inference with the model and applies the postprocessing.\n",
    "\n",
    "# The 'devices' argument can be used to specify which device(s) to use for inference with the model.\n",
    "# Hence it can be used to specify whether to use the cpu, a single gpu or multiple gpus (not implemented yet).\n",
    "# By default (devices=None) a gpu will be used if available and otherwise the cpu will be used.\n",
    "devices = None\n",
    "\n",
    "# The 'weight_format' argument can be used to specify which weight format available in the model to use.\n",
    "# By default (weight_format=None) the weight format with highest priority (as defined by bioimageio.core) will be used.\n",
    "weight_format = None\n",
    "\n",
    "prediction_pipeline = bioimageio.core.create_prediction_pipeline(\n",
    "    model_resource, devices=devices, weight_format=weight_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c73742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the prediction pipeline to run prediction for the image we loaded before.\n",
    "# The prediction pipeline always returns a tuple (even if the model only has a single output tensor).\n",
    "# So we access the first element of the prediction to get the predicted tensor.\n",
    "prediction = prediction_pipeline(input_array)[0]\n",
    "show_images(\n",
    "    input_image, prediction, names=[\"image\", \"prediction\"]\n",
    ")  # show the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f235e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction pipeline expects inputs to have a shape that fits the model exactly.\n",
    "# So if the input does not fit the expected input shape the prediction will fail.\n",
    "# E.g. if we crop the input to shape [1, 1, 250, 250] it will not work for our example model,\n",
    "# which expects a spatial shape that is a multiple of 16\n",
    "cropped_image = input_image[:, :, :250, :250]\n",
    "cropped_array = xr.DataArray(cropped_image, dims=tuple(model_resource.inputs[0].axes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the prediction pipeline to an image with the wrong shape will fail!\n",
    "prediction_pipeline(cropped_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, we can use the function `predict_with_padding`, which will pad the image to a shape that fits the model.\n",
    "prediction = bioimageio.core.predict_with_padding(prediction_pipeline, cropped_array)\n",
    "show_images(\n",
    "    cropped_image, prediction, names=[\"image\", \"prediction\"]\n",
    ")  # show the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is also the function `predict_with_tiling`, which will run prediction for patches in a sliding window fashion.\n",
    "# This is especially helpful for large inputs that do not fit into the model as a single input.\n",
    "\n",
    "# The `tiling` argument is used to specify the tile size and the `halo`, which is the part of the patch\n",
    "# that is cropped in order to reduce boundary artifacts.\n",
    "# Alternatively, `tiling` can also be set to `True`, than the tile size and halo will be deduced from the model config\n",
    "# (this is also the default behavior when the `tiling` parameter is not passed).\n",
    "tiling = {\n",
    "    \"tile\": {\"x\": 128, \"y\": 128},\n",
    "    \"halo\": {\"x\": 16, \"y\": 16},\n",
    "}  # use a tile size of 128x128 and crop a halo of 16 pixels\n",
    "\n",
    "# if `verbose` is set to True a progress bar will be printed\n",
    "prediction = bioimageio.core.predict_with_tiling(\n",
    "    prediction_pipeline, cropped_array, tiling=tiling, verbose=True\n",
    ")\n",
    "show_images(cropped_image, prediction, names=[\"image\", \"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba91499",
   "metadata": {},
   "source": [
    "### Convenience prediction functions\n",
    "\n",
    "`bioimageio.core` also contains a few convenience functions to directly predict images that are stored on disc:\n",
    "- `predict_image` can be used to run prediction for a single image\n",
    "- `predict_images` to run prediction for many images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The convenience function `predict_image` can be used to run prediction for an image stored on disc.\n",
    "from bioimageio.core.prediction import predict_image\n",
    "\n",
    "# The filepath where the output should be stored; supports most common image formats as well as npy fileformat.\n",
    "outputs = [\"prediction.tif\"]\n",
    "predict_image(model_resource, model_resource.test_inputs, outputs)\n",
    "\n",
    "# The output tensor contains 2 channels, which is not supported by normal tif.\n",
    "# Thus, these 2 channels are stored as 2 separate images.\n",
    "fg_pred = imageio.imread(\"prediction-c0.tif\")\n",
    "bd_pred = imageio.imread(\"prediction-c1.tif\")\n",
    "show_images(\n",
    "    input_image,\n",
    "    fg_pred,\n",
    "    bd_pred,\n",
    "    names=[\"image\", \"foreground-prediction\", \"boundary-prediction\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879618df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The convenience function `predict_images` can be use to run prediction for many images stored on disc\n",
    "# Note: this only works for models which have a single input and output!\n",
    "from bioimageio.core.prediction import predict_images\n",
    "\n",
    "# Here we use a small subset of the dsb challenge data for prediction.\n",
    "# The original data is available at https://github.com/stardist/stardist/releases/download/0.1.0/dsb2018.zip.\n",
    "# We have added a few images to the repository so that the notebook runs out of the box.\n",
    "\n",
    "# Get all paths to the images in the \"example-images\" folder.\n",
    "from glob import glob\n",
    "\n",
    "inputs = glob(\"./example-images/*.png\")\n",
    "\n",
    "# Create an output folder and specify the output path for each image.\n",
    "output_folder = \"./predictions\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "outputs = [os.path.join(output_folder, os.path.split(inp)[1]) for inp in inputs]\n",
    "\n",
    "print(len(inputs), \"images for prediction were found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7cf46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model at hand can only predict images which have a spatial shape that is\n",
    "# a multiple of 16. To run with images of other sizes we pass the `padding`\n",
    "# argument to `predict_images` and specify that the input is padded to the next bigger\n",
    "# size that is divisible by 16 (mode: dynamic).\n",
    "# As an alternative `\"mode\": \"fixed\"` will pad to a fixed shape, e.g.\n",
    "# `{\"x\": 512, \"y\": 512, \"mode\": \"fixed\"}` will always pad to a size of 512x512.\n",
    "# The padding is cropped again after the prediction to restore the input shape.\n",
    "padding = {\"x\": 16, \"y\": 16, \"mode\": \"dynamic\"}\n",
    "predict_images(model_resource, inputs, outputs, padding=padding, verbose=True)\n",
    "\n",
    "# check the first input/output\n",
    "show_images(\n",
    "    inputs[0],\n",
    "    outputs[0].replace(\".png\", \"-c0.png\"),\n",
    "    outputs[0].replace(\".png\", \"-c1.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of padding, we can also use tiling.\n",
    "# Here, we specify a tile size of 256 and a halo (= what's cropped from the tile on either side) of 16.\n",
    "tiling = {\n",
    "    \"tile\": {\"x\": 256, \"y\": 256},\n",
    "    \"halo\": {\"x\": 16, \"y\": 16},\n",
    "}\n",
    "predict_images(model_resource, inputs, outputs, tiling=tiling, verbose=True)\n",
    "\n",
    "# Check the first input output pair.\n",
    "show_images(\n",
    "    inputs[0],\n",
    "    outputs[0].replace(\".png\", \"-c0.png\"),\n",
    "    outputs[0].replace(\".png\", \"-c1.png\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
