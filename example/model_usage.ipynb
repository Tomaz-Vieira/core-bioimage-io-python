{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioimage Model Zoo Core  Example notebook\n",
    "\n",
    "This notebook shows how to interact with the `bioimageio.core` programmatically to explore, load, use, and export content from the [BioImage Model Zoo](https://bioimage.io).\n",
    "\n",
    "\n",
    "quick links:\n",
    "- [Create an input sample for a given model](#create_sample_for_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate human readable output error messages and load dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running the notebook locally you need to pip install the following dependencies into your local environment. Make sure to restart your notebook kernel after installing dependencies.\n",
    "\n",
    "```console\n",
    "pip install bioimageio.core==0.8.0 torch==2.5.1 matplotlib==3.10.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running in colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running this notebook through colab, there is no need to install dependencies manually, just run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# install dependencies if running in colab\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    %pip install bioimageio.core==0.8.0 torch==2.5.1 matplotlib==3.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imageio.v2 import imread\n",
    "\n",
    "from bioimageio.spec.utils import download\n",
    "\n",
    "import bioimageio.core\n",
    "\n",
    "from bioimageio.spec.pretty_validation_errors import (\n",
    "    enable_pretty_validation_errors_in_ipynb,\n",
    ")\n",
    "\n",
    "# Improve readiblity of validation errors\n",
    "enable_pretty_validation_errors_in_ipynb()\n",
    "\n",
    "# Function to display input and prediction output images\n",
    "def show_images(sample_tensor, prediction_tensor):\n",
    "    input_array = sample_tensor.members[\"input0\"].data\n",
    "\n",
    "    # Check for the number of channels to enable display\n",
    "    input_array = np.squeeze(input_array)\n",
    "    if len(input_array.shape) > 2:\n",
    "        input_array = input_array[0]\n",
    "\n",
    "    output_array = prediction_tensor.members[\"output0\"].data\n",
    "\n",
    "    # Check for the number of channels to enable display\n",
    "    output_array = np.squeeze(output_array)\n",
    "    if len(output_array.shape) > 2:\n",
    "        output_array = output_array[0]\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax1.set_title(\"Input\")\n",
    "    ax1.axis(\"off\")\n",
    "    plt.imshow(input_array)\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    ax2.set_title(\"Prediction\")\n",
    "    ax2.axis(\"off\")\n",
    "    plt.imshow(output_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect available models in the Bioimage Model Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://bioimage.io to browser available models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from the BioImage Model Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bioimage.io` resources may be identified via their bioimage.io __ID__, e.g. \"affable-shark\" or the [__DOI__](https://doi.org/) of their [__Zenodo__](https://zenodo.org/) backup.\n",
    "\n",
    "Both of these options may be version specific (\"affable-shark/1\" or a version specific [__Zenodo__](https://zenodo.org/) backup [__DOI__](https://doi.org/)).\n",
    "\n",
    "Alternatively, any rdf.yaml source, single file or in a .zip, may be loaded by providing its __local path__ or __URL__.\n",
    "\n",
    "**Note** -- For more detailed information about loading a model, inspecting a model's metadata and creating your own model visit [bioimageio.spec package example notebook](https://github.com/bioimage-io/spec-bioimage-io/blob/main/example/load_model_and_create_your_own.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_source = \"affable-shark\"\n",
    "#model_source = \"10.5281/zenodo.6287342\"\n",
    "#model_source = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/affable-shark/draft/files/rdf.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_model_description` is a function of the `bioimageio.spec` package, but as it is a sub-package of `bioimageio.core` it can also be called from it by `bioimageio.core.load_model_description`.\n",
    "\n",
    "To learn more about the functionalities of the `bioimageio.spec` package, see the [bioimageio.spec package example notebook](https://github.com/bioimage-io/spec-bioimage-io/blob/main/example/load_model_and_create_your_own.ipynb), also available as a [Google Colab](https://colab.research.google.com/github/bioimage-io/spec-bioimage-io/blob/main/example/load_model_and_create_your_own.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import load_model_description\n",
    "from bioimageio.core import test_model\n",
    "\n",
    "model = load_model_description(model_source)\n",
    "test_summary = test_model(model) #Test model to check environment compatibility  \n",
    "assert test_summary.status == \"passed\", test_summary.display() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bioimageio.core` implements the functionality to run a prediction with models described in the `bioimage.io` format.\n",
    "\n",
    "This includes functions to run predictions on `numpy.ndarray`/`xarray.DataArray` as input and convenience functions to run predictions for images stored on disc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `predict` function \n",
    "\n",
    "The most direct way to run a model prediction is using the `bioimageio.core` convenience function `predict`, to which you pass the model you want to predict with and the input you want to predict on, along with optional arguments with default values. The input can be a range of types including; `numpy.ndarray`, `xarray.DataArray`, bioimageio `Tensor` or `pathlib.Path` to data. The union of all these types are contained within the `TensorSource` object.\n",
    "\n",
    "`bioimageio.core.Tensors/xarray.DataArrays` are like numpy arrays, but they have annotated axes.\n",
    "\n",
    "However, sometimes a model requires multiple inputs to be passed in at once (e.g a raw data input and a mask input). To easily facilitate this inputs can be passed in as a mapping between input id and `TensorSource`. For example defining mulitple `numpy.ndarray` inputs could be done manually done as follows:\n",
    "\n",
    "```console\n",
    "inputs = {\"raw_input\": np.array([1,2,3]), \"mask_input\": np.array()}\n",
    "```\n",
    "\n",
    "To make things more convinent multiple inputs can instead be passed via a bioimageio `Sample` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import predict  # , predict_many\n",
    "from bioimageio.core import Sample\n",
    "\n",
    "# predict_many(model=model, inputs=[sample])\n",
    "\n",
    "prediction: Sample = predict(model=model, inputs=sample)\n",
    "\n",
    "# show the prediction result\n",
    "show_images(sample, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test image and convert into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec.model import v0_5\n",
    "from bioimageio.spec.utils import load_array\n",
    "\n",
    "assert isinstance(model, v0_5.ModelDescr)\n",
    "input_image = load_array(model.inputs[0].test_tensor)\n",
    "print(f\"array shape: {input_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Tensor` (light wrapper around an `xarray.DataArray`) from the test input image. \n",
    "\n",
    "`bioimageio.core.Tensors/xarray.DataArrays` are like numpy arrays, but they have annotated axes.\n",
    "\n",
    "The axes are used to validate that the axes of the input image match the axes expected by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import Tensor\n",
    "\n",
    "test_input_tensor = Tensor.from_numpy(input_image, dims=model.inputs[0].axes)\n",
    "\n",
    "# print the axis annotations ('dims') and the shape of the input array\n",
    "print(f\"tensor shape: {test_input_tensor.tagged_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of tensors is called a `Sample`.\n",
    "\n",
    "In the case of the `affable-shark` model it only has one input, but for models with multiple inputs a `Sample` includes a tensor for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import Sample\n",
    "\n",
    "sample = Sample(members={\"raw\": test_input_tensor}, stat={}, id=\"sample-from-numpy\")\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bioimageio.core` provides the helper function `create_sample_for_model` to automatically create the `Sample` for the given model.\n",
    "<a id='create_sample_for_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core.digest_spec import create_sample_for_model\n",
    "from bioimageio.spec.utils import download\n",
    "\n",
    "input_paths = {ipt.id: download(ipt.test_tensor).path for ipt in model.inputs}\n",
    "print(f\"input paths: {input_paths}\")\n",
    "assert isinstance(model, v0_5.ModelDescr)\n",
    "sample = create_sample_for_model(\n",
    "    model=model, inputs=input_paths, sample_id=\"my_demo_sample\"\n",
    ")\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also  a helper function `get_test_inputs` to directly import the test input sample for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core.digest_spec import get_test_inputs\n",
    "\n",
    "test_sample = get_test_inputs(model)\n",
    "\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create a prediciton pipeline\n",
    "\n",
    "The `prediction_pipeline` function is used to run a prediction with a given model.\n",
    "\n",
    "It applies the __pre-processing__, if indicated in the model rdf.yaml, runs __inference__ with the model and applies the __post-processing__, again if specified in the model rdf.yaml.\n",
    "\n",
    "The `devices` argument can be used to specify which device(s), CPU, a single GPU, or multiple GPUs (not implemented yet), to use for inference with the model.\n",
    "\n",
    "The default is `devices=None`, this will use a __GPU__ if available, otherwise it uses the __CPU__.\n",
    "\n",
    "\n",
    "The `weight_format` argument can be used to specify which of the model's available weight formats to use.\n",
    "\n",
    "The deafult is `weight_format=None`, this will use the weight format with highest priority (as defined by bioimageio.core).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import create_prediction_pipeline\n",
    "\n",
    "devices = None\n",
    "weight_format = None\n",
    "\n",
    "prediction_pipeline = create_prediction_pipeline(\n",
    "    model, devices=devices, weight_format=weight_format\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the new prediction pipeline to run a prediction for the previously loaded test image.\n",
    "\n",
    "The prediction pipeline returns a `Sample` object, which will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction: Sample = prediction_pipeline.predict_sample_without_blocking(sample)\n",
    "\n",
    "# show the prediction result\n",
    "show_images(sample, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Prediction without a PredicitionPipeline\n",
    "\n",
    "`bioimageio.core` has two convenience functions `predict` and `predict_many` which allow the prediction of images without creating a `PredictionPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import predict  # , predict_many\n",
    "\n",
    "# predict_many(model=model, inputs=[sample])\n",
    "\n",
    "prediction: Sample = predict(model=model, inputs=sample)\n",
    "\n",
    "# show the prediction result\n",
    "show_images(sample, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Recover input and output tensors as numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example code shows how to recover the image information from the input and output tensors as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_input_list = []\n",
    "np_output_list = []\n",
    "\n",
    "# iterate over the number of tensors inside the input sample\n",
    "for ipt in range(len(sample.members.keys())):\n",
    "    input_array = sample.members[f\"input{ipt}\"].data\n",
    "\n",
    "    # Check for the number of channels to enable display\n",
    "    input_array = np.squeeze(input_array)\n",
    "    if len(input_array.shape) > 2:\n",
    "        input_array = input_array[0]\n",
    "\n",
    "    np_input_list.append(input_array)\n",
    "\n",
    "\n",
    "# iterate over the number of tensors inside the output prediction\n",
    "for out in range(len(prediction.members.keys())):\n",
    "    output_array = prediction.members[f\"output{ipt}\"].data\n",
    "\n",
    "    # Check for the number of channels to enable display\n",
    "    output_array = np.squeeze(output_array)\n",
    "    if len(output_array.shape) > 2:\n",
    "        output_array = output_array[0]\n",
    "\n",
    "    np_output_list.append(output_array)\n",
    "\n",
    "plt.imshow(np_input_list[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
