{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daf2216",
   "metadata": {},
   "source": [
    "# bioimageio.core usage examples\n",
    "\n",
    "Checkout [load_model_and_create_your_own.ipynb](https://github.com/bioimage-io/spec-bioimage-io/blob/main/example/) for examples on model creation, loading and inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ba149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    %pip install bioimageio.core \"napari[all]\" pytorch onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74613461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for showing multiple images in napari\n",
    "from bioimageio.core import Tensor\n",
    "from typing import Any, Dict, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import napari\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "def show_images(images: Dict[str, Union[Tensor, NDArray[Any], Path]]):\n",
    "    v = napari.Viewer()\n",
    "    for name, im in images.items():\n",
    "        if isinstance(im, Path):\n",
    "            im = imageio.imread(im)\n",
    "        elif isinstance(im, Tensor):\n",
    "            im = im.data\n",
    "        print(f\"napari viewer: adding {name}\")\n",
    "        v.add_image(im, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2deb81f",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "\n",
    "We will use a model that predicts boundaries in images of plant cells [kaggle nucles segmentation challenge](https://www.kaggle.com/c/data-science-bowl-2018).\n",
    "Find the model on bioimage.io here: [\"affable-shark](https://bioimage.io/#/?id=10.5281%2Fzenodo.5764892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.spec import load_description\n",
    "\n",
    "model = load_description(\"affable-shark/draft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de51dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model alternative\n",
    "from bioimageio.spec import load_description\n",
    "\n",
    "model = load_description(\"emotional-cricket/draft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46da8c",
   "metadata": {},
   "source": [
    "Let's briefly checkout the validation summary created upon loading the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce884f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validation_summary.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f21529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function 'test_model' from 'bioimageio.core.resource_tests' can be used to fully test the model,\n",
    "# including running prediction for the test input(s) and checking that they agree with the test output(s)\n",
    "# before using a model, it is recommended to check that it properly works with this function\n",
    "# 'test_model' returns a dict with 'status'='passed'/'failed' and more detailed information\n",
    "from bioimageio.core import test_model\n",
    "\n",
    "test_summary = test_model(model)\n",
    "test_summary.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c75014",
   "metadata": {},
   "source": [
    "## Prediction with the model\n",
    "\n",
    "`bioimageio.core` implements functionality to run prediction with models desribed in the `bioimage.io` format.\n",
    "This includes functions to run prediction on `numpy.ndarray`s/`xarray.DataArrays` as input and convenience functions to run predictions for images stored on disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the example image for this model, which is stored in numpy file format.\n",
    "from bioimageio.spec.utils import load_array\n",
    "from bioimageio.spec.model import v0_5\n",
    "\n",
    "assert isinstance(model, v0_5.ModelDescr)\n",
    "input_image = load_array(model.inputs[0].test_tensor)\n",
    "print(f\"array shape: {input_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import Sample, Tensor\n",
    "\n",
    "# Create a `Tensor` (light wrapper around an `xarray.DataArray`) from the test input image.\n",
    "# `bioimageio.core.Tensors/xarray.DataArrays` are like numpy arrays, but they have annotated axes.\n",
    "# The axes are used to validate that the axes of the input image match the axes expected by a model.\n",
    "test_input_tensor = Tensor.from_numpy(input_image, dims=model.inputs[0].axes)\n",
    "\n",
    "# print the axis annotations ('dims') and the shape of the input array\n",
    "print(f\"tensor shape: {test_input_tensor.tagged_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can create a sample --- a collection of tensors.\n",
    "# In this case our model only has one input, but for models with multiple inputs a `Sample` includes a tensor for each input.\n",
    "sample = Sample(members={\"raw\": test_input_tensor}, stat=None, id=\"sample-from-numpy\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786dce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut: helper function `create_sample_for_model` to create a sample for a given model directly\n",
    "\n",
    "from bioimageio.core.digest_spec import create_sample_for_model\n",
    "from bioimageio.spec.utils import download\n",
    "\n",
    "input_paths = {ipt.id: download(ipt.test_tensor).path for ipt in model.inputs}\n",
    "print(f\"input paths: {input_paths}\")\n",
    "assert isinstance(model, v0_5.ModelDescr)\n",
    "sample = create_sample_for_model(model=model, inputs=input_paths, sample_id=\"my_demo_sample\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff89c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut: get test input sample for a given model\n",
    "from bioimageio.core.digest_spec import get_test_inputs\n",
    "\n",
    "test_sample = get_test_inputs(model)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import create_prediction_pipeline\n",
    "\n",
    "# Next, create a 'prediction_pipeline'. The prediction_pipeline is used to run prediction with a given model.\n",
    "# This means it applies the preprocessing, runs inference with the model and applies the postprocessing.\n",
    "\n",
    "# The 'devices' argument can be used to specify which device(s) to use for inference with the model.\n",
    "# Hence it can be used to specify whether to use the cpu, a single gpu or multiple gpus (not implemented yet).\n",
    "# By default (devices=None) a gpu will be used if available and otherwise the cpu will be used.\n",
    "devices = None\n",
    "\n",
    "# The 'weight_format' argument can be used to specify which weight format available in the model to use.\n",
    "# By default (weight_format=None) the weight format with highest priority (as defined by bioimageio.core) will be used.\n",
    "weight_format = None\n",
    "\n",
    "prediction_pipeline = create_prediction_pipeline(\n",
    "    model, devices=devices, weight_format=weight_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c73742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the prediction pipeline to run prediction for the image we loaded before.\n",
    "# The prediction pipeline returns a `Sample` object.\n",
    "prediction: Sample = prediction_pipeline.predict_sample_without_blocking(sample)\n",
    "\n",
    "# show the prediction result\n",
    "show_images({**sample.members, **prediction.members})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b102c2",
   "metadata": {},
   "source": [
    "there are convenience functions `predict` and `predict_many` that can be used to predict images without explicit creation of a `PredictionPipeline`... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioimageio.core import predict#, predict_many\n",
    "\n",
    "predict(model=model, inputs=sample)\n",
    "# predict_many(model=model, inputs=[sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae04a0",
   "metadata": {},
   "source": [
    "# parts below are not up to date yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f235e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `PredictionPipeline.predict_sample_without_blocking` and `.predict_sample_block` expects the tensor members of the given sample to have a shape that can be processed by the model exactly.\n",
    "# So if the input does not fit the expected input shape the prediction might fail.\n",
    "# If the model specifies that an input is `concatenatable`, then we can create tiles/blocks that fit the model description and stitch (possibly overlaying) output tiles/blocks together.\n",
    "# Do demonstrate this we load the sample image.\n",
    "from pprint import pprint\n",
    "\n",
    "large_input_sample = create_sample_for_model(model=model, inputs={ipt.id: ipt.sample_tensor.download().path for ipt in model.inputs}, sample_id=\"sample input\")\n",
    "pprint({m: t.tagged_shape for m, t in large_input_sample.members.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the prediction pipeline to an image with the wrong shape might fail!\n",
    "\n",
    "_ = prediction_pipeline.predict_sample_without_blocking(large_input_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, we can use the method `predict_sample_with_blocking`, which will block/pad the image to a shape that fits the model.\n",
    "large_output_sample = prediction_pipeline.predict_sample_with_blocking(large_input_sample)\n",
    "\n",
    "# show the prediction result\n",
    "show_images(\n",
    "    {**large_input_sample.members, **large_output_sample.members}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
