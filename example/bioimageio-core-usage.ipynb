{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daf2216",
   "metadata": {},
   "source": [
    "# bioimageio.core usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ba149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "import bioimageio.core\n",
    "import imageio\n",
    "# we use napari for visualising images, you can install it via `pip install napari` or`conda install napari`\n",
    "import napari\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74613461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for showing multiple images in napari\n",
    "def show_images(*images, names=None):\n",
    "    v = napari.Viewer()\n",
    "    for i, im  in enumerate(images):\n",
    "        name = None if names is None else names[i]\n",
    "        if isinstance(im, str):\n",
    "            im = imageio.imread(im)\n",
    "        v.add_image(im, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2deb81f",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "\n",
    "We will use a model that predicts foreground and boundaries in images of nuclei from the [kaggle nucles segmentation challenge](https://www.kaggle.com/c/data-science-bowl-2018).\n",
    "Find the model on bioimage.io here: https://bioimage.io/#/?id=10.5072%2Fzenodo.881940\n",
    "\n",
    "First, we will use `bioimageio.core.load_resource_description` to load the model and inspec the obtained model resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de51dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model can be loaded using different representations:\n",
    "\n",
    "# the doi of the zenodo entry corresponding to the model\n",
    "rdf_doi = \"10.5281/zenodo.6287342\"\n",
    "\n",
    "# the url of the yaml file containing the model resource description\n",
    "rdf_url = \"https://zenodo.org/record/6287342/files/rdf.yaml\"\n",
    "\n",
    "# filepath to the downloaded model (either zipped package or yaml)\n",
    "# to download it from the website:\n",
    "# - go to https://bioimage.io/#/?id=10.5281%2Fzenodo.5764892%2F5764893\n",
    "# - click the download icon\n",
    "# - select \"ilastik\" weight format\n",
    "rdf_path = \"/home/pape/Downloads/nuclei-segmentation-boundarymodel_pytorch_state_dict.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce884f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from link to rdf.yaml\n",
    "model_resource = bioimageio.core.load_resource_description(rdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1230b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from doi\n",
    "model_resource = bioimageio.core.load_resource_description(rdf_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from path to the zipped model files\n",
    "model_resource = bioimageio.core.load_resource_description(rdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the \"model_resource\" instance returned by load_resource_description\n",
    "# contains the information stored in the resource description (see https://github.com/bioimage-io/spec-bioimage-io/blob/gh-pages/model_spec_latest.md)\n",
    "\n",
    "# we can e.g. check what weight formats are available in the model (pytorch_state_dict for the model used here)\n",
    "print(\"Available weight formats for this model:\", model_resource.weights.keys())\n",
    "# or where the (downloaded) weight files are stored\n",
    "print(\"Pytorch state dict weights are stored at:\", model_resource.weights[\"pytorch_state_dict\"].source)\n",
    "print()\n",
    "# or what inputs the model expects\n",
    "print(\"The model requires as inputs:\")\n",
    "for inp in model_resource.inputs:\n",
    "    print(\"Input with axes:\", inp.axes, \"and shape\", inp.shape)\n",
    "print()\n",
    "# and what the model outputs are\n",
    "print(\"The model returns the following outputs:\")\n",
    "for out in model_resource.outputs:\n",
    "    print(\"Output with axes:\", out.axes, \"and shape\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f21529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function 'test_model' from 'bioimageio.core.resource_tests' can be used to fully test the model,\n",
    "# including running prediction for the test input(s) and checking that they agree with the test output(s)\n",
    "# before using a model, it is recommended to check that it properly works with this function\n",
    "# 'test_model' returns a dict with 'status'='passed'/'failed' and more detailed information\n",
    "from bioimageio.core.resource_tests import test_model\n",
    "test_result = test_model(model_resource)\n",
    "if test_result[\"status\"] == \"failed\":\n",
    "    print(\"model test:\", test_result[\"name\"])\n",
    "    print(\"The model test failed with:\", test_result[\"error\"])\n",
    "    print(\"with the traceback:\")\n",
    "    print(\"\".join(test_result[\"traceback\"]))\n",
    "else:\n",
    "    test_result[\"status\"] == \"passed\"\n",
    "    print(\"The model passed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c75014",
   "metadata": {},
   "source": [
    "## Prediction with the model\n",
    "\n",
    "`bioimageio.core` implements functionality to run prediction with models in the `bioimage.io` format.\n",
    "This includes functions to run prediction with `xarray.DataArrays` as input and convenience functions to run predictions for images stored on disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the example image for this model, which is stored in numpy file format.\n",
    "input_image = np.load(model_resource.test_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an xarray.DataArray from the input image.\n",
    "# DataArrays are like numpy arrays, but they have annotated axes.\n",
    "# The axes are used to validate that the axes of the input image match the axes expected by a model.\n",
    "input_array = xr.DataArray(input_image, dims=tuple(model_resource.inputs[0].axes))\n",
    "# print the axis annotations ('dims') and the shape of the input array\n",
    "print(input_array.dims)\n",
    "print(input_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, create a 'prediction_pipeline'. The prediction_pipeline is used to run prediction with a given model.\n",
    "# This means it applies the preprocessing, runs inference with the model and applies the postprocessing.\n",
    "\n",
    "# The 'devices' argument can be used to specify which device(s) to use for inference with the model.\n",
    "# Hence it can be used to specify whether to use the cpu, a single gpu or multiple gpus (not implemented yet).\n",
    "# By default (devices=None) a gpu will be used if available and otherwise the cpu will be used.\n",
    "devices = None\n",
    "\n",
    "# The 'weight_format' argument can be used to specify which weight format available in the model to use.\n",
    "# By default (weight_format=None) the weight format with highest priority (as defined by bioimageio.core) will be used.\n",
    "weight_format = None\n",
    "\n",
    "prediction_pipeline = bioimageio.core.create_prediction_pipeline(\n",
    "    model_resource, devices=devices, weight_format=weight_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c73742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the prediction pipeline to run prediction for the image we loaded before.\n",
    "# The prediction pipeline always returns a tuple (even if the model only has a single output tensor).\n",
    "# So we access the first element of the prediction to get the predicted tensor.\n",
    "prediction = prediction_pipeline(input_array)[0]\n",
    "show_images(input_image, prediction, names=[\"image\", \"prediction\"])  # show the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f235e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction pipeline expects inputs to have a shape that fits the model exactly.\n",
    "# So if the input does not fit the expected input shape the prediction will fail.\n",
    "# E.g. if we crop the input to shape [1, 1, 250, 250] it will not work for our example model,\n",
    "# which expects a spatial shape that is a multiple of 16\n",
    "cropped_image = input_image[:, :, :250, :250]\n",
    "cropped_array = xr.DataArray(cropped_image, dims=tuple(model_resource.inputs[0].axes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the prediction pipeline to an image with the wrong shape will fail!\n",
    "prediction_pipeline(cropped_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, we can use the function `predict_with_padding`, which will pad the image to a shape that fits the model.\n",
    "prediction = bioimageio.core.predict_with_padding(prediction_pipeline, cropped_array)\n",
    "show_images(cropped_image, prediction, names=[\"image\", \"prediction\"])  # show the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is also the function `predict_with_tiling`, which will run prediction for patches in a sliding window fashion.\n",
    "# This is especially helpful for large inputs that do not fit into the model as a single input.\n",
    "\n",
    "# The `tiling` argument is used to specify the tile size and the `halo`, which is the part of the patch\n",
    "# that is cropped in order to reduce boundary artifacts.\n",
    "# Alternatively, `tiling` can also be set to `True`, than the tile size and halo will be deduced from the model config\n",
    "# (this is also the default behavior when the `tiling` parameter is not passed).\n",
    "tiling = {\"tile\": {\"x\": 128, \"y\": 128}, \"halo\": {\"x\": 16, \"y\": 16}}  # use a tile size of 128x128 and crop a halo of 16 pixels\n",
    "\n",
    "# if `verbose` is set to True a progress bar will be printed \n",
    "prediction = bioimageio.core.predict_with_tiling(prediction_pipeline, cropped_array, tiling=tiling, verbose=True)\n",
    "show_images(cropped_image, prediction, names=[\"image\", \"prediction\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba91499",
   "metadata": {},
   "source": [
    "### Convenience prediction functions\n",
    "\n",
    "`bioimageio.core` also contains a few convenience functions to directly predict images that are stored on disc:\n",
    "- `predict_image` can be used to run prediction for a single image\n",
    "- `predict_images` to run prediction for many images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The convenience function `predict_image` can be used to run prediction for an image stored on disc.\n",
    "from bioimageio.core.prediction import predict_image\n",
    "\n",
    "# The filepath where the output should be stored; supports most common image formats as well as npy fileformat.\n",
    "outputs = [\"prediction.tif\"]\n",
    "predict_image(\n",
    "    model_resource, model_resource.test_inputs, outputs\n",
    ")\n",
    "\n",
    "# The output tensor contains 2 channels, which is not supported by normal tif.\n",
    "# Thus, these 2 channels are stored as 2 separate images.\n",
    "fg_pred = imageio.imread(\"prediction-c0.tif\")\n",
    "bd_pred = imageio.imread(\"prediction-c1.tif\")\n",
    "show_images(input_image, fg_pred, bd_pred, names=[\"image\", \"foreground-prediction\", \"boundary-prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879618df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The convenience function `predict_images` can be use to run prediction for many images stored on disc\n",
    "# Note: this only works for models which have a single input and output!\n",
    "from bioimageio.core.prediction import predict_images\n",
    "\n",
    "# Here we use a small subset of the dsb challenge data for prediction.\n",
    "# The original data is available at https://github.com/stardist/stardist/releases/download/0.1.0/dsb2018.zip.\n",
    "# We have added a few images to the repository so that the notebook runs out of the box.\n",
    "\n",
    "# Get all paths to the images in the \"example-images\" folder.\n",
    "from glob import glob\n",
    "inputs = glob(\"./example-images/*.png\")\n",
    "\n",
    "# Create an output folder and specify the output path for each image.\n",
    "output_folder = \"./predictions\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "outputs = [os.path.join(output_folder, os.path.split(inp)[1]) for inp in inputs]\n",
    "\n",
    "print(len(inputs), \"images for prediction were found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7cf46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model at hand can only predict images which have a spatial shape that is\n",
    "# a multiple of 16. To run with images of other sizes we pass the `padding`\n",
    "# argument to `predict_images` and specify that the input is padded to the next bigger\n",
    "# size that is divisible by 16 (mode: dynamic).\n",
    "# As an alternative `\"mode\": \"fixed\"` will pad to a fixed shape, e.g.\n",
    "# `{\"x\": 512, \"y\": 512, \"mode\": \"fixed\"}` will always pad to a size of 512x512.\n",
    "# The padding is cropped again after the prediction to restore the input shape.\n",
    "padding = {\"x\": 16, \"y\": 16, \"mode\": \"dynamic\"}\n",
    "predict_images(\n",
    "    model_resource, inputs, outputs, padding=padding, verbose=True\n",
    ")\n",
    "\n",
    "# check the first input/output\n",
    "show_images(inputs[0], outputs[0].replace(\".png\", \"-c0.png\"), outputs[0].replace(\".png\", \"-c1.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of padding, we can also use tiling.\n",
    "# Here, we specify a tile size of 256 and a halo (= what's cropped from the tile on either side) of 16.\n",
    "tiling = {\n",
    "    \"tile\": {\"x\": 256, \"y\": 256},\n",
    "    \"halo\": {\"x\": 16, \"y\": 16},\n",
    "}\n",
    "predict_images(\n",
    "    model_resource, inputs, outputs, tiling=tiling, verbose=True\n",
    ")\n",
    "\n",
    "# Check the first input output pair.\n",
    "show_images(inputs[0], outputs[0].replace(\".png\", \"-c0.png\"), outputs[0].replace(\".png\", \"-c1.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8fd710",
   "metadata": {},
   "source": [
    "## Create a biomiage.io model package\n",
    "\n",
    "`bioimageio.core` also implements functionality to create a model package compatible with the [bioimageio model spec](https://github.com/bioimage-io/spec-bioimage-io/blob/gh-pages/model_spec_latest.md) ready to be shared via\n",
    "the [bioimage.io model zoo](https://bioimage.io/#/).\n",
    "Here, we will use this functionality to create two models, one that adds thresholding as post-processing to the outputs and another one that also adds weights in torchscript format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the python file defining the architecture.\n",
    "# this is only required for models with pytorch_state_dict weights\n",
    "def get_architecture_source(rdf):\n",
    "    # here, we need the raw resource, which contains the information from the resource description\n",
    "    # before evaluation, e.g. the file and name of the python file with the model architecture\n",
    "    raw_resource = bioimageio.core.load_raw_resource_description(rdf)\n",
    "    # the python file defining the architecture for the pytorch weihgts\n",
    "    model_source = raw_resource.weights[\"pytorch_state_dict\"].architecture\n",
    "    # download the source file if necessary\n",
    "    source_file = bioimageio.core.resource_io.utils.resolve_source(\n",
    "        model_source.source_file\n",
    "    )\n",
    "    # if the source file path does not exist, try combining it with the root path of the model\n",
    "    if not os.path.exists(source_file):\n",
    "        source_file = os.path.join(raw_resource.root_path, os.path.split(source_file)[1])\n",
    "    assert os.path.exists(source_file), source_file\n",
    "    class_name = model_source.callable_name\n",
    "    return f\"{source_file}:{class_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5962d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first new model: add thresholding of outputs as post-processing\n",
    "# the convenience function `build_model` creates a biomageio model spec compatible package (=zipped folder)\n",
    "from bioimageio.core.build_spec import build_model\n",
    "\n",
    "# create a subfolder to store the files for the new model\n",
    "model_root = \"./new_model\"\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "\n",
    "# create the expected output tensor (= outputs thresholded at 0.5)\n",
    "threshold = 0.5\n",
    "new_output = prediction > threshold\n",
    "new_output_path = f\"{model_root}/new_test_output.npy\"\n",
    "np.save(new_output_path, new_output)\n",
    "\n",
    "# add thresholding as post-processing procedure to our model\n",
    "preprocessing = [[{\"name\": prep.name, \"kwargs\": prep.kwargs} for prep in inp.preprocessing] for inp in model_resource.inputs]\n",
    "postprocessing = [[{\"name\": \"binarize\", \"kwargs\": {\"threshold\": threshold}}]]\n",
    "\n",
    "# get the model architecture\n",
    "# note that this is only necessary for pytorch state dict models\n",
    "model_source = get_architecture_source(rdf_doi)\n",
    "\n",
    "# we use the `parent` field to indicate that the new model is created based on\n",
    "# the nucleus segmentation model we have obtained from bioimage.io\n",
    "# this field is optional and only needs to be given for models that are created based on other models from bioimage.io\n",
    "# the parent is specified via it's doi and the hash of its rdf file\n",
    "model_root_folder = os.path.split(model_resource.weights[\"pytorch_state_dict\"].source)[0]\n",
    "rdf_file = os.path.join(model_root_folder, \"rdf.yaml\")\n",
    "with open(rdf_file, \"rb\") as f:\n",
    "    rdf_hash = hashlib.sha256(f.read()).hexdigest()\n",
    "parent = {\"uri\": rdf_doi, \"sha256\": rdf_hash}\n",
    "\n",
    "# the name of the new model and where to save the zipped model package\n",
    "name = \"new-model1\"\n",
    "zip_path = os.path.join(model_root, f\"{name}.zip\")\n",
    "\n",
    "# `build_model` needs some additional information about the model, like citation information\n",
    "# all this additional information is passed as plain python types and will be converted into the bioimageio representation internally  \n",
    "# for more informantion, check out the function signature\n",
    "# https://github.com/bioimage-io/core-bioimage-io-python/blob/main/bioimageio/core/build_spec/build_model.py#L252\n",
    "cite = [{\"text\": cite_entry.text, \"url\": cite_entry.url} for cite_entry in model_resource.cite]\n",
    "\n",
    "# the training data used for the model can also be specified by linking to a dataset available on bioimage.io\n",
    "training_data = {\"id\": \"ilastik/stradist_dsb_training_data\"}\n",
    "\n",
    "# the axes descriptions for the inputs / outputs\n",
    "input_axes = [\"bcyx\"]\n",
    "output_axes = [\"bcyx\"]\n",
    "\n",
    "# the pytorch_state_dict weight file\n",
    "weight_file = model_resource.weights[\"pytorch_state_dict\"].source\n",
    "\n",
    "# the path to save the new model with torchscript weights\n",
    "zip_path = f\"{model_root}/new_model2.zip\"\n",
    "\n",
    "# build the model! it will be saved to 'zip_path'\n",
    "new_model_raw = build_model(\n",
    "    weight_uri=weight_file,\n",
    "    test_inputs=model_resource.test_inputs,\n",
    "    test_outputs=[new_output_path],\n",
    "    input_axes=input_axes,\n",
    "    output_axes=output_axes,\n",
    "    output_path=zip_path,\n",
    "    name=name,\n",
    "    description=\"nucleus segmentation model with thresholding\",\n",
    "    authors=[{\"name\": \"Jane Doe\"}],\n",
    "    license=\"CC-BY-4.0\",\n",
    "    documentation=model_resource.documentation,\n",
    "    covers=[str(cover) for cover in model_resource.covers],\n",
    "    tags=[\"nucleus-segmentation\"],\n",
    "    cite=cite,\n",
    "    parent=parent,\n",
    "    architecture=model_source,\n",
    "    model_kwargs=model_resource.weights[\"pytorch_state_dict\"].kwargs,\n",
    "    preprocessing=preprocessing,\n",
    "    postprocessing=postprocessing,\n",
    "    training_data=training_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0616547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new model from the zipped package, run prediction and check the result\n",
    "new_model = bioimageio.core.load_resource_description(zip_path)\n",
    "prediction = predict_numpy(new_model, input_image)\n",
    "show_images(input_image, prediction, names=[\"input\", \"binarized-prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85287bf7",
   "metadata": {},
   "source": [
    "## Add different weight format and package model with new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `convert_weigths_to_pytorch_script` creates torchscript weigths based on the weights loaded from pytorch_state_dict\n",
    "from bioimageio.core.weight_converter.torch import convert_weights_to_torchscript\n",
    "# `add_weights` adds new weights to the model specification\n",
    "from bioimageio.core.build_spec import add_weights\n",
    "\n",
    "# the path to save the newly created torchscript weights\n",
    "weight_path = os.path.join(model_root, \"weights.torchscript\")\n",
    "convert_weights_to_torchscript(new_model, weight_path)\n",
    "\n",
    "# the path to save the new model with torchscript weights\n",
    "zip_path = f\"{model_root}/new_model2.zip\"\n",
    "new_model2_raw = add_weights(new_model_raw, weight_path, weight_type=\"torchscript\", output_path=zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15dd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new model from the zipped package, run prediction and check the result\n",
    "new_model = bioimageio.core.load_resource_description(zip_path)\n",
    "prediction = predict_numpy(new_model, input_image, weight_format=\"torchscript\")\n",
    "show_images(input_image, prediction, names=[\"input\", \"binarized-prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models in the biomageio.core format can also directly be exported as zipped packages\n",
    "# using `bioimageio.core.export_resource_package`\n",
    "bioimageio.core.export_resource_package(new_model2_raw, output_path=\"another_model.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
